{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6aac3ee8",
   "metadata": {},
   "source": [
    "# üì© Spam‚ÄìHam Classification (Baseline NLP Model)\n",
    "\n",
    "## Project Objective\n",
    "The objective of this project is to build a **baseline NLP classification model**\n",
    "to classify SMS messages as **Spam** or **Ham**.\n",
    "\n",
    "This baseline will serve as a reference point for evaluating more advanced models\n",
    "in the future.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdaa93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries Imported Successfully\n"
     ]
    }
   ],
   "source": [
    "def libraries():\n",
    "    import pandas as pd\n",
    "    import numpy as np \n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    from sklearn.metrics import confusion_matrix,accuracy_score,f1_score,recall_score,classification_report\n",
    "    \n",
    "    return pd,np,plt,train_test_split,TfidfVectorizer,LogisticRegression,MultinomialNB,confusion_matrix,accuracy_score,f1_score,recall_score,classification_report\n",
    "\n",
    "\n",
    "\n",
    "pd,np,plt,train_test_split,TfidfVectorizer,LogisticRegression,MultinomialNB,confusion_matrix,accuracy_score,f1_score,recall_score,classification_report = libraries()\n",
    "print(\"Libraries Imported Successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8634907a",
   "metadata": {},
   "source": [
    "## üìä Dataset Overview\n",
    "\n",
    "- The dataset consists of SMS text messages.\n",
    "- Each message is labeled as:\n",
    "  - **Spam (1)**\n",
    "  - **Ham (0)**\n",
    "\n",
    "### Features\n",
    "- `message`: Text content of the SMS\n",
    "\n",
    "### Target Variable\n",
    "- `label`: Binary classification label (Spam / Ham)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3af59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>Messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Labels                                           Messages\n",
       "0       0  Go until jurong point, crazy.. Available only ...\n",
       "1       0                      Ok lar... Joking wif u oni...\n",
       "2       1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       0  U dun say so early hor... U c already then say...\n",
       "4       0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dataset():\n",
    "    df = pd.read_csv(r\"C:\\Users\\chaud\\Downloads\\spam.csv\",encoding= \"latin\")\n",
    "    df = df[[\"v1\",\"v2\"]]\n",
    "    df.columns = [\"Labels\",\"Messages\"]\n",
    "    df[\"Labels\"] = df[\"Labels\"].map({\"ham\":0,\"spam\":1})\n",
    "    return df\n",
    "df = dataset()\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a6b350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Dataset info---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Labels    5572 non-null   int64 \n",
      " 1   Messages  5572 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 87.2+ KB\n",
      "\n",
      "--- Descriptive Statistics ---\n",
      "             Labels\n",
      "count  5572.000000\n",
      "mean      0.134063\n",
      "std       0.340751\n",
      "min       0.000000\n",
      "25%       0.000000\n",
      "50%       0.000000\n",
      "75%       0.000000\n",
      "max       1.000000\n",
      "\n",
      "--- Unique Values per Column ---\n",
      " Labels         2\n",
      "Messages    5169\n",
      "dtype: int64\n",
      "\n",
      "--- Value Counts for Labels ---\n",
      " Labels\n",
      "0    4825\n",
      "1     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def dataset_info(df):\n",
    "    print(\"---Dataset info---\")\n",
    "    info = df.info()\n",
    "    description = df.describe()\n",
    "    unique_sum = df.nunique()\n",
    "    value_count = df[\"Labels\"].value_counts()if \"Labels\" in df.columns else \"Column 'Labels' not found\"\n",
    "    return info ,description,unique_sum,value_count\n",
    "info,description,unique_sum,value_count = dataset_info(df) \n",
    "\n",
    "print(\"\\n--- Descriptive Statistics ---\\n\", description)\n",
    "print(\"\\n--- Unique Values per Column ---\\n\", unique_sum)\n",
    "print(\"\\n--- Value Counts for Labels ---\\n\", value_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e92db2",
   "metadata": {},
   "source": [
    "## üîÄ Train‚ÄìTest Split\n",
    "\n",
    "The dataset is split into training and testing sets to evaluate model performance\n",
    "on unseen data.\n",
    "\n",
    "- **Training set** is used to train the model\n",
    "- **Test set** is used only for evaluation\n",
    "\n",
    "This helps prevent overfitting and data leakage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690737f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sample : 3900\n",
      "Testing sample : 1672\n",
      "\n",
      "--- x_train ---\n",
      " 4912    Goal! Arsenal 4 (Henry, 7 v Liverpool 2 Henry ...\n",
      "2541      I dont. Can you send it to me. Plus how's mode.\n",
      "5323                           Aah bless! How's your arm?\n",
      "5171                         Oh k. . I will come tomorrow\n",
      "2532                                            Yup ok...\n",
      "                              ...                        \n",
      "3185    Happy birthday to you....dear.with lots of lov...\n",
      "607     what I meant to say is cant wait to see u agai...\n",
      "552     Sure, if I get an acknowledgement from you tha...\n",
      "763     Nothing but we jus tot u would ask cos u ba gu...\n",
      "3393    Bull. Your plan was to go floating off to IKEA...\n",
      "Name: Messages, Length: 3900, dtype: object\n",
      "\n",
      "--- x_train_type ---\n",
      " <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "def splitting_data(df,train_test_split,random_state = 42,test_size = 0.30):\n",
    "    x_train , x_test ,y_train ,y_test = train_test_split(df[\"Messages\"],df[\"Labels\"],random_state= random_state,stratify=df[\"Labels\"],test_size=test_size)\n",
    "    return x_train , x_test ,y_train ,y_test \n",
    "x_train , x_test ,y_train ,y_test  = splitting_data(df,train_test_split,random_state = 42,test_size = 0.30)\n",
    "print(f\"Training sample :\",len(x_train))\n",
    "print(f\"Testing sample :\",len(x_test))\n",
    "print(\"\\n--- x_train ---\\n\",x_train)\n",
    "print(\"\\n--- x_train_type ---\\n\",type(x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ea29b4",
   "metadata": {},
   "source": [
    "## üß† Text Vectorization (TF-IDF)\n",
    "\n",
    "Machine learning models cannot work directly with raw text.\n",
    "Therefore, text messages are converted into numerical features using:\n",
    "\n",
    "- **TF-IDF Vectorizer**\n",
    "- Learns vocabulary from training data only\n",
    "- Reduces importance of common words\n",
    "\n",
    "This step converts text into a sparse numerical matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cc23bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer : TfidfVectorizer()\n",
      "x_train_vec : <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 51578 stored elements and shape (3900, 7202)>\n",
      "  Coords\tValues\n",
      "  (0, 2930)\t0.4048550489723281\n",
      "  (0, 986)\t0.424946486354178\n",
      "  (0, 3158)\t0.424946486354178\n",
      "  (0, 3865)\t0.19529997364521248\n",
      "  (0, 5507)\t0.20242752448616405\n",
      "  (0, 7002)\t0.0933484902055576\n",
      "  (0, 5714)\t0.1725981461699518\n",
      "  (0, 5668)\t0.20242752448616405\n",
      "  (0, 2796)\t0.19877581458981025\n",
      "  (0, 7123)\t0.212473243177089\n",
      "  (0, 4734)\t0.1702367610950114\n",
      "  (0, 1472)\t0.11103261888339745\n",
      "  (0, 1212)\t0.212473243177089\n",
      "  (0, 6441)\t0.0539842523443838\n",
      "  (0, 2912)\t0.1236887276677332\n",
      "  (0, 4055)\t0.212473243177089\n",
      "  (0, 769)\t0.12991524136520063\n",
      "  (0, 558)\t0.212473243177089\n",
      "  (0, 4184)\t0.14086199719960968\n",
      "  (1, 6441)\t0.15850991863481007\n",
      "  (1, 2227)\t0.3422498571791928\n",
      "  (1, 1509)\t0.25863523023826496\n",
      "  (1, 7154)\t0.1637240840081839\n",
      "  (1, 5571)\t0.31637853608419586\n",
      "  (1, 3487)\t0.23470864133096522\n",
      "  :\t:\n",
      "  (3898, 4495)\t0.15656967633973623\n",
      "  (3898, 3024)\t0.22338061100200432\n",
      "  (3898, 2535)\t0.22338061100200432\n",
      "  (3899, 7002)\t0.2725083838876886\n",
      "  (3899, 6441)\t0.2363909902992306\n",
      "  (3899, 4101)\t0.11434763902672622\n",
      "  (3899, 7157)\t0.23439061724621427\n",
      "  (3899, 6330)\t0.09677140964836868\n",
      "  (3899, 3372)\t0.10597322115643798\n",
      "  (3899, 3111)\t0.12105395454247984\n",
      "  (3899, 2927)\t0.14488163951071723\n",
      "  (3899, 1531)\t0.1909432737696334\n",
      "  (3899, 5824)\t0.1282140800078821\n",
      "  (3899, 6856)\t0.15754013080341292\n",
      "  (3899, 2015)\t0.1554730842016926\n",
      "  (3899, 889)\t0.2173747024828866\n",
      "  (3899, 3862)\t0.21219967937292\n",
      "  (3899, 7052)\t0.21600988125248655\n",
      "  (3899, 4548)\t0.2017960972878323\n",
      "  (3899, 4856)\t0.22341595791333665\n",
      "  (3899, 7005)\t0.23067290665025197\n",
      "  (3899, 3341)\t0.2850655649286359\n",
      "  (3899, 4147)\t0.2954691470137236\n",
      "  (3899, 1440)\t0.31013217241148905\n",
      "  (3899, 2685)\t0.31013217241148905\n",
      "x_test_vec : <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 20717 stored elements and shape (1672, 7202)>\n",
      "  Coords\tValues\n",
      "  (0, 226)\t0.2434796763784852\n",
      "  (0, 957)\t0.14468465225218108\n",
      "  (0, 1183)\t0.1959769820707632\n",
      "  (0, 1551)\t0.21463119448434906\n",
      "  (0, 1683)\t0.20003100424119982\n",
      "  (0, 2679)\t0.3192996733414213\n",
      "  (0, 3111)\t0.13559157224681784\n",
      "  (0, 3216)\t0.23382250037100127\n",
      "  (0, 3374)\t0.30287573514714816\n",
      "  (0, 3862)\t0.23768317412834392\n",
      "  (0, 4615)\t0.2821840201141853\n",
      "  (0, 4625)\t0.14853173553275326\n",
      "  (0, 5220)\t0.25024643856527434\n",
      "  (0, 5557)\t0.25213079765389973\n",
      "  (0, 5895)\t0.25024643856527434\n",
      "  (0, 5899)\t0.29663164363974115\n",
      "  (0, 6441)\t0.08825988973483484\n",
      "  (0, 6987)\t0.27832334635684264\n",
      "  (0, 7154)\t0.09116318856229448\n",
      "  (1, 1023)\t0.31377307350854244\n",
      "  (1, 1458)\t0.30441164290077055\n",
      "  (1, 2223)\t0.3933117635440465\n",
      "  (1, 3688)\t0.3464345395276409\n",
      "  (1, 4909)\t0.730868645166558\n",
      "  (2, 44)\t0.23386534506069806\n",
      "  :\t:\n",
      "  (1669, 4615)\t0.20393516365968448\n",
      "  (1669, 4620)\t0.1940852426179866\n",
      "  (1669, 4655)\t0.11932213917267162\n",
      "  (1669, 5895)\t0.180853786062767\n",
      "  (1669, 6441)\t0.2551426554965921\n",
      "  (1669, 6584)\t0.1309488242948904\n",
      "  (1669, 6678)\t0.11398484015313443\n",
      "  (1670, 873)\t0.18676177549583675\n",
      "  (1670, 2124)\t0.40868266703132167\n",
      "  (1670, 3688)\t0.2581332512015092\n",
      "  (1670, 3799)\t0.34017641582674674\n",
      "  (1670, 4462)\t0.24523192225988402\n",
      "  (1670, 4597)\t0.4257178871566445\n",
      "  (1670, 5529)\t0.44237846487695925\n",
      "  (1670, 5631)\t0.3170209569595134\n",
      "  (1670, 6975)\t0.24030259223970504\n",
      "  (1670, 7154)\t0.14291607084326635\n",
      "  (1671, 986)\t0.5142838872954736\n",
      "  (1671, 1458)\t0.21420265335549135\n",
      "  (1671, 1810)\t0.5142838872954736\n",
      "  (1671, 2720)\t0.19235217341047797\n",
      "  (1671, 2950)\t0.2503844959637412\n",
      "  (1671, 4462)\t0.2315889442302387\n",
      "  (1671, 4625)\t0.21989818106731668\n",
      "  (1671, 5454)\t0.4727166024912159\n",
      "Feature_names : ['00' '000' '008704050406' ... '√ª¬™t' '√ª¬™ve' '√ª√≤']\n"
     ]
    }
   ],
   "source": [
    "def vectorization(x_train,x_test,TfidfVectorizer):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    x_train_vec = vectorizer.fit_transform(x_train)\n",
    "    x_test_vec = vectorizer.transform(x_test)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    return vectorizer,x_train_vec,x_test_vec,feature_names\n",
    "vectorizer,x_train_vec,x_test_vec,feature_names = vectorization(x_train,x_test,TfidfVectorizer)\n",
    "print(f\"Vectorizer :\",vectorizer)\n",
    "print(f\"x_train_vec :\",x_train_vec)\n",
    "print(f\"x_test_vec :\",x_test_vec)\n",
    "print(f\"Feature_names :\",feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7647031",
   "metadata": {},
   "source": [
    "## ü§ñ Baseline Models\n",
    "\n",
    "The following baseline machine learning models are used:\n",
    "\n",
    "### 1. Logistic Regression\n",
    "- Strong linear classifier\n",
    "- Performs well on high-dimensional text data\n",
    "\n",
    "### 2. Multinomial Naive Bayes\n",
    "- Designed specifically for text classification\n",
    "- Fast and effective for word-frequency features\n",
    "\n",
    "These models provide a strong baseline for NLP problems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946e2cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models : {'logisticregression': LogisticRegression(max_iter=1000), 'MultinomialNB': MultinomialNB()}\n",
      "predictions : {'logisticregression': array([1, 0, 1, ..., 1, 0, 0], shape=(1672,)), 'MultinomialNB': array([1, 0, 1, ..., 1, 0, 0], shape=(1672,))}\n"
     ]
    }
   ],
   "source": [
    "def model_select(x_train_vec,x_test_vec,y_train):\n",
    "    models = {\n",
    "        \"logisticregression\":LogisticRegression(max_iter=1000,class_weight= \"balanced\"),\n",
    "        \"MultinomialNB\":MultinomialNB()\n",
    "    }\n",
    "    predictions = {}\n",
    "\n",
    "    for name,model in models.items():\n",
    "        model.fit(x_train_vec,y_train)\n",
    "        predictions[name] = model.predict(x_test_vec)\n",
    "    return models,predictions  \n",
    "\n",
    "models,predictions = model_select(x_train_vec,x_test_vec,y_train)\n",
    "print(f\"models :\",models)\n",
    "print(f\"predictions :\",predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1bc895",
   "metadata": {},
   "source": [
    "## üìä Results and Model Comparison\n",
    "\n",
    "The table below summarizes the performance of baseline models\n",
    "using key evaluation metrics.\n",
    "\n",
    "- Metrics are shown per model\n",
    "- Higher **F1-score** indicates better balance between false positives\n",
    "  and false negatives\n",
    "- Confusion matrix helps analyze classification errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2bbc8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logisticregression</th>\n",
       "      <th>MultinomialNB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>confusion_matrix</th>\n",
       "      <td>[[1447, 1], [48, 176]]</td>\n",
       "      <td>[[1448, 0], [70, 154]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_score</th>\n",
       "      <td>0.970694</td>\n",
       "      <td>0.958134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.877805</td>\n",
       "      <td>0.814815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_score</th>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.6875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classification_report</th>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      logisticregression  \\\n",
       "confusion_matrix                                  [[1447, 1], [48, 176]]   \n",
       "accuracy_score                                                  0.970694   \n",
       "f1_score                                                        0.877805   \n",
       "recall_score                                                    0.785714   \n",
       "classification_report                precision    recall  f1-score   ...   \n",
       "\n",
       "                                                           MultinomialNB  \n",
       "confusion_matrix                                  [[1448, 0], [70, 154]]  \n",
       "accuracy_score                                                  0.958134  \n",
       "f1_score                                                        0.814815  \n",
       "recall_score                                                      0.6875  \n",
       "classification_report                precision    recall  f1-score   ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#baseline models comparison \n",
    "def metrics(predictions,y_test):\n",
    "        metrics_model = {}\n",
    "        for name,y_pred in predictions.items():\n",
    "                metrics_model[name] = {\n",
    "                        \"confusion_matrix\" : confusion_matrix(y_test,y_pred),\n",
    "                        \"accuracy_score\" : accuracy_score(y_test,y_pred),\n",
    "                        \"f1_score\" : f1_score(y_test,y_pred),\n",
    "                        \"recall_score\"  : recall_score(y_test,y_pred),\n",
    "                        \"classification_report\" : classification_report(y_test,y_pred)\n",
    "\n",
    "                }\n",
    "        table = pd.DataFrame.from_dict(metrics_model,orient= \"columns\")\n",
    "        table = table.loc[[\"confusion_matrix\",\"accuracy_score\",\"f1_score\",\"recall_score\",\"classification_report\" ]]\n",
    "        table.loc[\"confusion_matrix\"] = table.loc[\"confusion_matrix\"].apply(lambda x: x.tolist())        \n",
    "                \n",
    "        return metrics_model,table\n",
    "metrics_model,table =  metrics(predictions,y_test)\n",
    "table\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef386c56",
   "metadata": {},
   "source": [
    "## üèÜ Best Model Selection\n",
    "\n",
    "Based on the evaluation metrics:\n",
    "\n",
    "- The model with the **highest F1-score** is selected as the best baseline model\n",
    "- This model demonstrates better spam detection performance\n",
    "\n",
    "This baseline model will be used for further improvements\n",
    "such as hyperparameter tuning or advanced NLP models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e2ed11",
   "metadata": {},
   "source": [
    "## ‚úÖ Conclusion\n",
    "\n",
    "- A complete baseline NLP pipeline was implemented\n",
    "- TF-IDF was used for text vectorization\n",
    "- Multiple baseline models were evaluated\n",
    "- The best model was selected using F1-score is Logistic Regression\n",
    "\n",
    "### Future Improvements\n",
    "- Hyperparameter tuning\n",
    "- N-grams experimentation\n",
    "- Advanced models (SVC, RandomForestClassifier, Transformers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beafd5ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e639111",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpproject1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
